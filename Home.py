# (venv)í™˜ê²½ì—ì„œ streamlit run Home.py ëª…ë ¹ì–´ ì‹¤í–‰
from crawl_data import get_vectorstore
from rag_system import get_medical_chain, get_retriever, format_docs
from langchain_community.chat_models import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler
from langchain.callbacks import StdOutCallbackHandler
import streamlit as st
import os

# messagesì— message ì €ì¥


def save_message(message, role):
    st.session_state["messages"].append({"role": role, "message": message})

# uiì— messageë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.


def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)

# uiì— ê¸°ì¡´ì— ì£¼ê³ ë°›ì€ messageë¥¼ ê·¸ë¦½ë‹ˆë‹¤.


def paint_history():
    for message in st.session_state["messages"]:
        send_message(message["message"], message["role"], save=False)


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Dr. Navi",
    page_icon="ğŸ©º",
)

# ì±—ë´‡ ì½œë°± í•¸ë“¤ëŸ¬ (ì¢Œë¼ë¼ë¼ë½ ì“°ê²Œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.)


class ChatCallbackHandler(BaseCallbackHandler):
    message = ""

    def on_llm_start(self, *args, **kwargs):
        # ì±—ë´‡ì´ ëŒ€í™”ë¥¼ ì‹œì‘í•  ë•Œë§ˆë‹¤ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        # ì±—ë´‡ì´ ëŒ€í™”ë¥¼ ëë‚¼ ë•Œ ë©”ì„¸ì§€ë¥¼ messagesì— ì €ì¥í•©ë‹ˆë‹¤.
        save_message(self.message, "ai")
        # print()

    # í† í°ì´ ë„ì°©í• ë•Œë§ˆë‹¤ ë©”ì„¸ì§€ë¥¼ ê·¸ë ¤ì¤ë‹ˆë‹¤.
    def on_llm_new_token(self, token: str, *args, **kwargs):
        self.message += token
        self.message_box.markdown(self.message)
        # print(token, end="")


# llm ìƒì„±
# streamì´ trueì¸ llm
llm = ChatOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    temperature=0.1,
    model="gpt-4o-mini",
    streaming=True,
    callbacks=[ChatCallbackHandler()],
)

st.title('ğŸ©ºDr. Navi')
st.markdown("ì˜ë£Œ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. ì¦ìƒì„ ì…ë ¥í•˜ë©´ ì§„ë£Œê³¼ ì¶”ì²œ, ì£¼ì˜ì‚¬í•­ ë“±ì„ ì•ˆë‚´í•´ë“œë¦½ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
st.markdown("íŒ€ì› : ê¹€ë¯¼ì² , ì„ë™ì„±, ì§€ìš©ì„, ìµœìœ ì •, í—ˆí˜„ì¤€")
with st.expander("ì‚¬ìš©ì ì •ë³´ ì…ë ¥"):
    gender = st.radio("ì„±ë³„ì„ ì„ íƒí•´ì£¼ì„¸ìš”", ["ë‚¨ì„±", "ì—¬ì„±"], index=None)
    age = st.number_input("ë‚˜ì´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", min_value=0, max_value=120, value=20)

# message ê¸°ë¡ ì €ì¥ ì´ˆê¸°í™” -> messages
if "messages" not in st.session_state:
    st.session_state["messages"] = []
    save_message(
        "ì•ˆë…•í•˜ì„¸ìš”! ì˜ë£Œ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. ì¦ìƒì„ ì…ë ¥í•˜ë©´ ì§„ë£Œê³¼ ì¶”ì²œ, ì£¼ì˜ì‚¬í•­ ë“±ì„ ì•ˆë‚´í•´ë“œë¦½ë‹ˆë‹¤.\n\nex) ì½§ë¬¼ê³¼ ê¸°ì¹¨ì´ ë‚˜ì™€ìš”", "ai")

# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ê·¸ë¦½ë‹ˆë‹¤.
paint_history()


# ì‚¬ìš©ì ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.
message = st.chat_input("ì¦ìƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”...")
if message:  # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
    send_message(message, "human")
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ llmì— ì „ë‹¬í•©ë‹ˆë‹¤.
    with st.spinner("Thinking..."):
        # vectorstoreì„ pineconeì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        vectorstore = get_vectorstore()
        # medical_chainì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        medical_chain = get_medical_chain(llm)
        # retriverë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        retriver = get_retriever(vectorstore)

        if gender is None:
            gender = "ë‚¨ì„±"
        if age is None:
            age = 20
    # aiê°€ ëŒ€ë‹µí•œ ë©”ì‹œì§€ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
    with st.chat_message("ai"):
        medical_chain.invoke({
            "context": format_docs(retriver.invoke(message)),
            "input": message,
            "sex": gender,
            "age": age
        })
